{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ca2f13",
   "metadata": {},
   "source": [
    "# CARPENTER Algorithm: Closed Pattern Discovery by Transposing Tables\n",
    "\n",
    "## Course Project - Data Mining and Data Warehousing\n",
    "\n",
    "**Team Members:**\n",
    "- Member 1: Data Preprocessing & Input Handling\n",
    "- Member 2: CARPENTER Algorithm Core Implementation  \n",
    "- Member 3: Visualization & Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook demonstrates the **CARPENTER** (Closed pAttern mineR by transPositioN for ExTremely long pattERns) algorithm - an efficient method for discovering closed frequent itemsets from transactional databases.\n",
    "\n",
    "### Key Features:\n",
    "- Optimized for extremely long transactional databases\n",
    "- Uses table transposition for efficiency\n",
    "- Discovers closed patterns (no redundant supersets)\n",
    "- Memory-efficient for large datasets\n",
    "\n",
    "### Algorithm Benefits:\n",
    "1. **Efficiency**: Faster than traditional algorithms for long databases\n",
    "2. **Completeness**: Discovers all closed frequent patterns\n",
    "3. **Space-saving**: Closed patterns eliminate redundancy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb631ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Dataset Loading and Preprocessing\n",
    "\n",
    "In this section, we'll load a transactional dataset and prepare it for pattern mining.\n",
    "\n",
    "**Member 1's Contribution**: Data loading and preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cea32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Implementing the Table Transposition Algorithm\n",
    "\n",
    "Table transposition is the key innovation of CARPENTER. It converts transaction-based view (rows = transactions) to item-based view (rows = items).\n",
    "\n",
    "**Why Transpose?**\n",
    "- Extremely long databases have many transactions but fewer items\n",
    "- Item-based view is more compact and efficient\n",
    "- Faster support counting through bit-vector operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b258d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference in representation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Horizontal format visualization\n",
    "sample_horizontal = matrix[:10, :10]\n",
    "im1 = ax1.imshow(sample_horizontal, cmap='Blues', aspect='auto')\n",
    "ax1.set_title('Horizontal Format\\n(Transaction-based)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Items')\n",
    "ax1.set_ylabel('Transactions')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_xticklabels(item_list[:10], rotation=45, ha='right')\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_yticklabels([f'T{i}' for i in range(1, 11)])\n",
    "plt.colorbar(im1, ax=ax1, label='Present (1) / Absent (0)')\n",
    "\n",
    "# Vertical format visualization\n",
    "sample_vertical = transposed_matrix[:10, :10]\n",
    "im2 = ax2.imshow(sample_vertical, cmap='Oranges', aspect='auto')\n",
    "ax2.set_title('Vertical Format\\n(Item-based)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Transactions')\n",
    "ax2.set_ylabel('Items')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_xticklabels([f'T{i}' for i in range(1, 11)], rotation=45, ha='right')\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_yticklabels(item_list[:10])\n",
    "plt.colorbar(im2, ax=ax2, label='Present (1) / Absent (0)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Both formats represent the same data, but vertical is more efficient for long databases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387068ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze closed patterns by length\n",
    "pattern_lengths = [p['length'] for p in closed_patterns]\n",
    "length_distribution = Counter(pattern_lengths)\n",
    "\n",
    "print(\"Closed Pattern Length Distribution:\")\n",
    "print(\"-\" * 50)\n",
    "for length in sorted(length_distribution.keys()):\n",
    "    count = length_distribution[length]\n",
    "    bar = \"â–ˆ\" * (count * 2)\n",
    "    print(f\"  Length {length}: {count:3d} patterns {bar}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Total Closed Patterns: {len(closed_patterns)}\")\n",
    "print(f\"Average Pattern Length: {np.mean(pattern_lengths):.2f}\")\n",
    "print(f\"Maximum Pattern Length: {max(pattern_lengths) if pattern_lengths else 0}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance metrics for our main run\n",
    "viz.plot_performance_metrics(stats, save_path='../results/performance_metrics.png')\n",
    "\n",
    "print(\"âœ“ Performance metrics dashboard created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cc721",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Algorithm Efficiency**: CARPENTER successfully discovered closed frequent patterns by utilizing table transposition\n",
    "2. **Pattern Discovery**: Found patterns that meet the minimum support threshold while eliminating redundancy\n",
    "3. **Performance**: Execution time varies with support threshold - lower support = more patterns but longer runtime\n",
    "\n",
    "### CARPENTER Advantages:\n",
    "\n",
    "âœ“ **Memory Efficient**: Transposed representation reduces memory footprint for long databases  \n",
    "âœ“ **Complete Results**: Discovers all closed frequent patterns without loss  \n",
    "âœ“ **Redundancy Elimination**: Closed patterns remove supersets with same support  \n",
    "âœ“ **Scalability**: Performs well on extremely long transactional databases\n",
    "\n",
    "### Team Contributions:\n",
    "\n",
    "- **Member 1**: Data preprocessing, loading, and matrix transformation\n",
    "- **Member 2**: Core CARPENTER algorithm implementation and optimization  \n",
    "- **Member 3**: Visualization, performance analysis, and result presentation\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Test on larger real-world datasets (retail, web logs, biological data)\n",
    "2. Compare with other frequent pattern mining algorithms (Apriori, FP-Growth, CHARM)\n",
    "3. Optimize support counting for very large databases\n",
    "4. Implement parallel processing for improved performance\n",
    "5. Create interactive dashboard for pattern exploration\n",
    "\n",
    "---\n",
    "\n",
    "## References:\n",
    "\n",
    "1. Pan, F., Cong, G., Tung, A. K., Yang, J., & Zaki, M. J. (2003). \"CARPENTER: Finding Closed Patterns in Long Biological Datasets\"\n",
    "2. Frequent Pattern Mining - Data Mining: Concepts and Techniques\n",
    "3. Closed Itemset Mining Algorithms\n",
    "\n",
    "---\n",
    "\n",
    "**Project completed successfully! ðŸŽ‰**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46947730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export patterns to CSV\n",
    "viz.export_patterns_to_csv(closed_patterns, '../results/closed_patterns.csv')\n",
    "\n",
    "# Generate comprehensive report\n",
    "viz.generate_report(closed_patterns, stats, '../results/analysis_report.txt')\n",
    "\n",
    "print(\"\\nâœ“ All results exported successfully!\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - results/closed_patterns.csv\")\n",
    "print(\"  - results/analysis_report.txt\")\n",
    "print(\"  - results/pattern_distribution.png\")\n",
    "print(\"  - results/support_distribution.png\")\n",
    "print(\"  - results/top_patterns.png\")\n",
    "print(\"  - results/cooccurrence_heatmap.png\")\n",
    "print(\"  - results/comparison_plot.png\")\n",
    "print(\"  - results/performance_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2dd2a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Export Results\n",
    "\n",
    "Export discovered patterns and analysis reports for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d19557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create item co-occurrence heatmap\n",
    "viz.create_pattern_heatmap(closed_patterns, item_list, save_path='../results/cooccurrence_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top patterns by support\n",
    "viz.plot_top_patterns(closed_patterns, top_n=15, save_path='../results/top_patterns.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize support distribution\n",
    "viz.plot_support_distribution(closed_patterns, save_path='../results/support_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pattern length distribution\n",
    "viz.plot_pattern_distribution(closed_patterns, save_path='../results/pattern_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33004988",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Visualization of Results\n",
    "\n",
    "Creating comprehensive visualizations for pattern analysis.\n",
    "\n",
    "**Member 3's Contribution**: Data visualization and result presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8bd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance metrics\n",
    "viz = PatternVisualizer()\n",
    "\n",
    "# Plot comparison of different support thresholds\n",
    "viz.plot_comparison(comparison_results, save_path='../results/comparison_plot.png')\n",
    "\n",
    "print(\"âœ“ Comparison visualization created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f97ea7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Performance Evaluation and Metrics\n",
    "\n",
    "Analyzing the algorithm's performance and efficiency.\n",
    "\n",
    "**Member 2 & 3's Contribution**: Performance analysis and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741447e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df['minsup_pct'] = comparison_df['minsup'] * 100\n",
    "\n",
    "print(\"\\nComparison Table:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df[['minsup_pct', 'total_closed_patterns', 'execution_time', \n",
    "                     'avg_pattern_length', 'max_pattern_length']].to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple support thresholds\n",
    "support_thresholds = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "comparison_results = []\n",
    "\n",
    "print(\"Running CARPENTER with different support thresholds...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for minsup in support_thresholds:\n",
    "    carpenter_test = CARPENTER(minsup=minsup, use_percentage=True)\n",
    "    patterns = carpenter_test.mine_patterns(transactions=transactions)\n",
    "    stats = carpenter_test.get_statistics()\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'minsup': minsup,\n",
    "        'total_closed_patterns': stats['total_closed_patterns'],\n",
    "        'execution_time': stats['execution_time'],\n",
    "        'avg_pattern_length': stats['avg_pattern_length'],\n",
    "        'max_pattern_length': stats['max_pattern_length']\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ“ MinSup={minsup*100:4.0f}%: {stats['total_closed_patterns']:3d} patterns in {stats['execution_time']:.3f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d55a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: CARPENTER Algorithm - Comparing Different Support Thresholds\n",
    "\n",
    "Let's run CARPENTER with different minimum support values to see how it affects the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c18e3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Closed Pattern Discovery\n",
    "\n",
    "**What are Closed Patterns?**\n",
    "\n",
    "A pattern P is **closed** if there exists no proper superset P' of P with the same support.\n",
    "\n",
    "**Example:**\n",
    "- If {A, B} has support 50 and {A, B, C} also has support 50\n",
    "- Then {A, B} is NOT closed (it has a superset with same support)\n",
    "- But {A, B, C} might be closed if no superset has support 50\n",
    "\n",
    "**Why Mine Closed Patterns?**\n",
    "- Eliminates redundancy\n",
    "- Smaller result set without information loss\n",
    "- All frequent patterns can be derived from closed patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eed5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display discovered patterns\n",
    "carpenter.print_patterns(limit=15)\n",
    "\n",
    "# Get and display statistics\n",
    "stats = carpenter.get_statistics()\n",
    "print(\"\\nAlgorithm Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c101597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CARPENTER with 15% minimum support\n",
    "carpenter = CARPENTER(minsup=0.15, use_percentage=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RUNNING CARPENTER ALGORITHM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: {len(transactions)} transactions, {len(item_list)} unique items\")\n",
    "print(f\"Minimum Support: {carpenter.minsup * 100}%\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Mine closed frequent patterns\n",
    "closed_patterns = carpenter.mine_patterns(transactions=transactions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708a89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Frequent Pattern Mining\n",
    "\n",
    "Now we'll discover frequent patterns that meet the minimum support threshold.\n",
    "\n",
    "**Member 2's Contribution**: CARPENTER algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c0ef3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Vertical to Horizontal Data Format Conversion\n",
    "\n",
    "Understanding the conversion between formats is crucial for CARPENTER's efficiency.\n",
    "\n",
    "**Format Comparison:**\n",
    "- **Horizontal (Transaction-based)**: Each row is a transaction\n",
    "- **Vertical (Item-based)**: Each row is an item, columns show which transactions contain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592141cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the table (vertical format)\n",
    "transposed_matrix = loader.transpose_table(matrix)\n",
    "\n",
    "print(f\"\\nTransposed Matrix (Vertical):\")\n",
    "print(f\"  Shape: {transposed_matrix.shape} (items Ã— transactions)\")\n",
    "print(f\"  Items: {transposed_matrix.shape[0]}\")\n",
    "print(f\"  Transactions: {transposed_matrix.shape[1]}\")\n",
    "print(f\"\\nSample of transposed matrix (first 5 items, first 10 transactions):\")\n",
    "print(pd.DataFrame(transposed_matrix[:5, :10],\n",
    "                   index=item_list[:5],\n",
    "                   columns=[f\"T{i}\" for i in range(1, 11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transaction matrix (horizontal format)\n",
    "matrix, item_list, trans_ids = loader.create_transaction_matrix()\n",
    "\n",
    "print(f\"Transaction Matrix (Horizontal):\")\n",
    "print(f\"  Shape: {matrix.shape} (transactions Ã— items)\")\n",
    "print(f\"  Transactions: {matrix.shape[0]}\")\n",
    "print(f\"  Items: {matrix.shape[1]}\")\n",
    "print(f\"\\nSample of transaction matrix (first 5 transactions, first 10 items):\")\n",
    "print(pd.DataFrame(matrix[:5, :10], \n",
    "                   columns=item_list[:10],\n",
    "                   index=[f\"T{i}\" for i in range(1, 6)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "cleaned_transactions = loader.preprocess_data(\n",
    "    remove_duplicates=True,\n",
    "    min_transaction_length=2\n",
    ")\n",
    "\n",
    "# Display statistics\n",
    "loader.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc52d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "loader = DataLoader()\n",
    "transactions = loader.load_dataset('../data/raw/sample_small.txt', delimiter=' ')\n",
    "\n",
    "print(f\"\\nâœ“ Loaded {len(transactions)} transactions\")\n",
    "print(f\"\\nFirst 5 transactions:\")\n",
    "for i, trans in enumerate(transactions[:5], 1):\n",
    "    print(f\"  T{i}: {sorted(trans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2db6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for demonstration\n",
    "print(\"Creating sample transactional datasets...\")\n",
    "\n",
    "# Create a small dataset for quick testing\n",
    "create_sample_dataset('../data/raw/sample_small.txt', \n",
    "                     num_transactions=100, \n",
    "                     num_items=15, \n",
    "                     avg_length=5)\n",
    "\n",
    "# Create a medium dataset for comprehensive analysis\n",
    "create_sample_dataset('../data/raw/sample_medium.txt', \n",
    "                     num_transactions=500, \n",
    "                     num_items=30, \n",
    "                     avg_length=8)\n",
    "\n",
    "print(\"\\nâœ“ Sample datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Import custom modules\n",
    "from data_preprocessing import DataLoader, create_sample_dataset\n",
    "from carpenter_algorithm import CARPENTER\n",
    "from visualization import PatternVisualizer\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
